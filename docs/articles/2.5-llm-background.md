# Background Job System in Rails 8: Solid Queue and Turbo Streams

In our journey to build a D&D character generator, we've reached a crucial milestone: implementing a robust background job system. This article explores how we're using Rails 8's Solid Queue and Turbo Streams to handle asynchronous content generation while maintaining a responsive user interface.

## The Challenge: Asynchronous Content Generation

Generating D&D character content using LLMs can take several seconds. A synchronous approach would leave users waiting, degrading the user experience. We need a system that can:

1. Handle multiple concurrent content generation requests
2. Provide real-time feedback on job progress
3. Allow job cancellation
4. Maintain state across page refreshes
5. Scale efficiently in production

## Current Progress

We've laid the foundation for our background job system:

### 1. Solid Queue Setup ✅

Our implementation uses Solid Queue, Rails 8's new first-party job processing system. The setup includes:

```ruby
# config/environments/development.rb
config.active_job.queue_adapter = :solid_queue
config.solid_queue.connects_to = { database: { writing: :queue } }

# config/queue.yml
default: &default
  dispatchers:
    - polling_interval: 1
      batch_size: 500
  workers:
    - queues: "*"
      threads: 3
      processes: <%= ENV.fetch("JOB_CONCURRENCY", 1) %>
      polling_interval: 0.1
```

This configuration provides:

- Separate database for job storage
- Configurable worker processes
- Flexible queue configuration
- Development-friendly defaults

### 2. Basic Job Infrastructure ✅

We've successfully implemented and tested our job processing system:

```ruby
# app/jobs/hello_world_job.rb
class HelloWorldJob < ApplicationJob
  queue_as :default

  def perform(*args)
    Rails.logger.info "Hello World from Solid Queue!"
  end
end

# app/controllers/test_jobs_controller.rb
class TestJobsController < ApplicationController
  def hello_world
    HelloWorldJob.perform_later
    render plain: "HelloWorldJob enqueued"
  end
end
```

Key achievements:

- Verified job queuing and processing
- Confirmed proper database transactions
- Tested job logging and completion
- Validated worker process functionality

### 1. User Job Counter Service ✅

We've implemented a thread-safe service to track and limit concurrent jobs per user:

```ruby
class UserJobCounter
  # Use Concurrent::Map for thread-safe operations
  @@job_counts = Concurrent::Map.new { |h, k| h[k] = 0 }

  class << self
    def increment(user_id)
      @@job_counts.compute(user_id) { |_k, v| v + 1 }
    end

    def decrement(user_id)
      @@job_counts.compute(user_id) { |_k, v| [v - 1, 0].max }
    end

    def count_for(user_id)
      @@job_counts[user_id] || 0
    end

    def can_enqueue?(user_id)
      # Get the max jobs limit, defaulting to 10 if not configured
      max_jobs = begin
        value = Rails.application.config.x.max_concurrent_jobs_per_user
        # Convert to integer, handling both numeric and hash-like objects
        case value
        when Integer
          value
        when Hash, ActiveSupport::OrderedOptions
          value.to_h.fetch(:value, 10)
        else
          value.to_i.nonzero? || 10
        end
      rescue StandardError => e
        Rails.logger.warn "Failed to get max_concurrent_jobs_per_user config: #{e.message}. Using default of 10."
        10
      end

      current_count = count_for(user_id)
      Rails.logger.debug "Checking job limit for user #{user_id}: current=#{current_count}, max=#{max_jobs}"

      current_count < max_jobs
    end

    # For testing and cleanup
    def reset!
      @@job_counts.clear
    end
  end
end
```

Key features:

- Thread-safe operation using `Concurrent::Map`
- Robust error handling and logging
- Configurable maximum jobs per user
- Safe increment/decrement operations
- Testing support with reset capability

We've also implemented a controller concern to enforce these limits:

```ruby
module JobLimiting
  extend ActiveSupport::Concern

  def check_job_limit!(user_id)
    unless UserJobCounter.can_enqueue?(user_id)
      respond_to do |format|
        format.html do
          flash[:alert] = "Maximum number of concurrent jobs reached"
          redirect_back(fallback_location: root_path)
        end
        format.json do
          render json: { error: "Maximum number of concurrent jobs reached" },
                 status: :too_many_requests
        end
      end
    end
  end
end
```

And our base job class handles the counting:

```ruby
class ApplicationJob < ActiveJob::Base
  before_perform :increment_job_count
  after_perform :decrement_job_count
  after_retry :decrement_job_count
  after_discard :decrement_job_count

  retry_on StandardError, wait: ->(attempts) { [10, 30, 60][attempts - 1] }, attempts: 3 do |job, error|
    Rails.logger.error "Job #{job.class.name} (#{job.job_id}) failed permanently: #{error.message}"
  end

  private

  def increment_job_count
    UserJobCounter.increment(arguments.first)
  end

  def decrement_job_count
    UserJobCounter.decrement(arguments.first)
  end
end
```

### 2. Job Cancellation System

We'll add the ability to cancel running jobs:

```ruby
class JobCancellation
  @@canceled_jobs = Set.new

  def self.mark_canceled(job_id)
    @@canceled_jobs << job_id.to_s
  end

  def self.canceled?(job_id)
    @@canceled_jobs.include?(job_id.to_s)
  end
end
```

### 3. Turbo Stream Integration

We'll implement real-time updates using Turbo Streams:

```ruby
# app/jobs/generate_background_job.rb
class GenerateBackgroundJob < ApplicationJob
  def perform(character_id)
    character = Character.find(character_id)

    # Update UI to show progress
    Turbo::StreamsChannel.broadcast_replace_to(
      "character_#{character.id}",
      target: "background_section",
      partial: "characters/generating_background"
    )

    # Generate content
    result = LlmService.generate_background(character)

    # Update UI with result
    Turbo::StreamsChannel.broadcast_replace_to(
      "character_#{character.id}",
      target: "background_section",
      partial: "characters/background",
      locals: { character: character }
    )
  end
end
```

### 4. Session Tracking

To maintain state across page refreshes:

```ruby
class CharactersController < ApplicationController
  def generate_background
    job = GenerateBackgroundJob.perform_later(@character.id)

    # Track job in session
    session[:active_jobs] ||= []
    session[:active_jobs] << job.job_id

    respond_to do |format|
      format.turbo_stream
    end
  end
end
```

## Production Considerations

Our implementation takes into account several production concerns:

1. **Scalability**

   - Separate database for job storage
   - Configurable worker processes
   - Connection pool management

2. **Reliability**

   - Automatic job retries
   - Error tracking
   - Job status monitoring

3. **Performance**
   - Efficient job polling
   - Optimized database indexes
   - Minimal memory footprint

## Testing Strategy

We're implementing comprehensive tests:

```ruby
class BackgroundJobTest < ActiveJob::TestCase
  test "enforces per-user job limit" do
    assert_no_enqueued_jobs do
      11.times { GenerateBackgroundJob.perform_later(user.id) }
    end

    assert_equal 10, UserJobCounter.count_for(user.id)
  end

  test "handles job cancellation" do
    job = GenerateBackgroundJob.perform_later(user.id)
    JobCancellation.mark_canceled(job.job_id)

    perform_enqueued_jobs
    assert_not_performed job
  end
end
```

## Real-Time Updates with Solid Cable

Our background job system needs to provide real-time updates to users about their job status. While Turbo Streams are great for basic updates, we can enhance our real-time capabilities using Rails 8's Solid Cable - a database-backed Action Cable adapter that eliminates the need for Redis.

### Solid Cable Configuration

We're leveraging Rails 8's built-in Solid Cable support with a dedicated database:

```ruby
# config/database.yml
development:
  primary:
    <<: *default
    database: storage/development.sqlite3
  cable:
    <<: *default
    database: storage/development_cable.sqlite3
    migrations_paths: db/cable_migrate

# config/cable.yml
development:
  adapter: solid_cable
  connects_to:
    database:
      writing: cable
  polling_interval: 0.1.seconds
  message_retention: 1.day
```

This configuration provides:

- Separate database for cable messages
- Fast polling (0.1 second intervals)
- 1-day message retention
- Automatic message cleanup

### Enhanced Job Progress Updates

We've enhanced our background job to provide more granular progress updates:

```ruby
class GenerateBackgroundJob < ApplicationJob
  include ActionCable::Channel::Broadcasting

  def perform(character_id)
    character = Character.find(character_id)

    broadcast_progress("Starting background generation...", 0)

    # Generate traits
    traits = LlmService.generate_traits(character)
    broadcast_progress("Generated personality traits...", 25)

    # Generate background
    background = LlmService.generate_background(character)
    broadcast_progress("Generated character background...", 75)

    # Final update
    character.update!(
      personality_traits: traits,
      background: background
    )

    broadcast_completion(character)
  end

  private

  def broadcast_progress(message, percentage)
    broadcast_to(
      "character_progress_#{arguments.first}",
      {
        status: "processing",
        message: message,
        percentage: percentage
      }
    )
  end

  def broadcast_completion(character)
    broadcast_to(
      "character_progress_#{character.id}",
      {
        status: "completed",
        message: "Generation complete!",
        percentage: 100,
        redirect_url: Rails.application.routes.url_helpers.character_path(character)
      }
    )
  end
end
```

### Client-Side Integration

Our view templates now include real-time progress updates:

```erb
<%# app/views/characters/show.html.erb %>
<div id="character-generation"
     data-controller="character-generation"
     data-character-generation-channel="character_progress_<%= @character.id %>">

  <div class="progress-bar"
       data-character-generation-target="progressBar"
       role="progressbar"
       aria-valuenow="0"
       aria-valuemin="0"
       aria-valuemax="100">
  </div>

  <div class="status-message"
       data-character-generation-target="statusMessage"
       aria-live="polite">
  </div>
</div>
```

And the corresponding Stimulus controller:

```javascript
// app/javascript/controllers/character_generation_controller.js
import { Controller } from "@hotwired/stimulus";
import { createConsumer } from "@rails/actioncable";

export default class extends Controller {
  static targets = ["progressBar", "statusMessage"];

  connect() {
    this.channel = createConsumer().subscriptions.create(
      { channel: "CharacterProgressChannel", id: this.channelValue },
      {
        received: this.handleUpdate.bind(this),
      }
    );
  }

  disconnect() {
    this.channel.unsubscribe();
  }

  handleUpdate(data) {
    this.progressBarTarget.style.width = `${data.percentage}%`;
    this.statusMessageTarget.textContent = data.message;

    if (data.status === "completed" && data.redirect_url) {
      window.location.href = data.redirect_url;
    }
  }
}
```

### Benefits of Solid Cable

By using Solid Cable instead of traditional Action Cable with Redis:

1. **Simplified Infrastructure**

   - No Redis dependency
   - Consistent database technology
   - Easier deployment

2. **Reliable Message Delivery**

   - Messages persisted in database
   - Automatic cleanup of old messages
   - No message size limitations

3. **Development Friendly**
   - Same setup in development and production
   - Easy to debug with SQL queries
   - Built-in message retention

## Conclusion

Our background job system demonstrates how Rails 8's conventions and tools can create a robust, scalable solution for asynchronous processing. By leveraging Solid Queue and Turbo Streams, we've built a system that provides a great user experience while maintaining code simplicity and reliability.

Next, we'll explore how this system integrates with our LLM service to handle streaming responses and partial updates.
